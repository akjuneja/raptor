{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912cd8c6-d405-4dfe-8897-46108e6a6af7",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9edc35",
   "metadata": {},
   "source": [
    "### Raptor implementation on Qasper dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8748d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DFKI\\RAGs\\raptor\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-15 23:25:58,912 - Loading faiss with AVX2 support.\n",
      "2025-01-15 23:25:59,542 - Successfully loaded faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "from raptor import RetrievalAugmentation \n",
    "from raptor import BaseSummarizationModel, BaseQAModel, BaseEmbeddingModel, RetrievalAugmentationConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from vertexai.generative_models import HarmCategory,HarmBlockThreshold\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf6b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can define your own Summarization model by extending the base Summarization Class. \n",
    "class GEMINISummarizationModel(BaseSummarizationModel):\n",
    "    def __init__(self, model_name=\"gemini-1.5-pro\"): \n",
    "        safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "        # top_k = 50, original raptor | Not supported in ChatVertexAI (1-41)\n",
    "        llm = ChatVertexAI(model=model_name, safety_settings= safety_settings, \n",
    "                           temperature=0.7, top_p=0.95, top_k=40, max_tokens=150,\n",
    "                           project=\"sovereign-cloud-420714\")\n",
    "        \n",
    "        sys_msg = SystemMessage(content = \"You are a helpful assistant.\")\n",
    "        user_msg = HumanMessagePromptTemplate.from_template(\n",
    "                template=[\n",
    "                    {\"type\": \"text\", \"text\": \"Write a summary of the following, including as many key details as possible: {context}:\"},\n",
    "                ],\n",
    "            )\n",
    "        chat_prompt = ChatPromptTemplate(messages=[sys_msg, user_msg])\n",
    "        self.summarization_chain = chat_prompt | llm\n",
    "\n",
    "    def summarize(self, context, max_tokens=150):\n",
    " \n",
    "        output = self.summarization_chain.invoke({\"context\": context})\n",
    "        summary = output.content.strip()\n",
    "        return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aa5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GEMINIQAModel(BaseQAModel):\n",
    "    def __init__(self, model_name= \"gemini-1.5-pro\"):\n",
    "        safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "        # top_k = 50, original raptor | Not supported in ChatVertexAI (1-41)\n",
    "        llm = ChatVertexAI(model=model_name, safety_settings= safety_settings, \n",
    "                           temperature=0.7, top_p=0.95, top_k=40, max_tokens=256,\n",
    "                           project=\"sovereign-cloud-420714\")\n",
    "        \n",
    "        sys_msg = SystemMessage(content = \"You are Question Answering Portal.\")\n",
    "        user_msg = HumanMessagePromptTemplate.from_template(\n",
    "                template=[\n",
    "                    {\"type\": \"text\", \"text\": \"Given Context: {context} Give the best full answer amongst the option to question {question}\"},\n",
    "                ]\n",
    "            )\n",
    "        chat_prompt = ChatPromptTemplate(messages=[sys_msg, user_msg])\n",
    "        self.qa_chain = chat_prompt | llm\n",
    "\n",
    "    def answer_question(self, context, question):\n",
    "        output = self.qa_chain.invoke({\"context\":context, \"question\":question})\n",
    "        answer = output.content.strip()\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa84224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBertEmbeddingModel(BaseEmbeddingModel):\n",
    "    def __init__(self, model_name=\"sentence-transformers/multi-qa-mpnet-base-cos-v1\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def create_embedding(self, text):\n",
    "        return self.model.encode(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6359134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 23:27:14,359 - Use pytorch device_name: cpu\n",
      "2025-01-15 23:27:14,360 - Load pretrained SentenceTransformer: sentence-transformers/multi-qa-mpnet-base-cos-v1\n"
     ]
    }
   ],
   "source": [
    "RAC = RetrievalAugmentationConfig(summarization_model=GEMINISummarizationModel(), qa_model=GEMINIQAModel(), embedding_model=SBertEmbeddingModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo run\n",
    "\n",
    "RA = RetrievalAugmentation(config=RAC)\n",
    "with open('demo/sample.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "RA.add_documents(text)\n",
    "question = \"How did Cinderella reach her happy ending?\"\n",
    "answer = RA.answer_question(question=question)\n",
    "print(\"Answer: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26642d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Length of samples 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]2025-01-16 00:07:09,742 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x0000023C98A4E090>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x0000023C99C87210>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-16 00:07:09,751 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x0000023C98A4E090>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x0000023C99C87210>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-16 00:07:09,753 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x0000023C98A4E090>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x0000023C99C87210>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.SBertEmbeddingModel object at 0x0000023C99C87210>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <__main__.GEMINIQAModel object at 0x0000023C981A8390>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-01-16 00:07:09,777 - Creating Leaf Nodes\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "2025-01-16 00:07:24,972 - Created 90 Leaf Embeddings\n",
      "2025-01-16 00:07:24,972 - Building All Nodes\n",
      "2025-01-16 00:07:24,977 - Using Cluster TreeBuilder\n",
      "2025-01-16 00:07:24,982 - Constructing Layer 0\n",
      "d:\\DFKI\\RAGs\\raptor\\env\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Async experiments \n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "\n",
    "from experiments import run\n",
    "\n",
    "data_path = \"data\\\\qasper-test-v0.3.0.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    samples = test_data[:25]\n",
    "    print(len(samples))\n",
    "results = await run(samples, RAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "748818f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-15 21:47:59,597 - Successfully initialized TreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x000001C144FB56D0>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x000001C119E0A410>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-15 21:47:59,597 - Successfully initialized ClusterTreeBuilder with Config \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x000001C144FB56D0>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x000001C119E0A410>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "2025-01-15 21:47:59,597 - Successfully initialized RetrievalAugmentation with Config \n",
      "        RetrievalAugmentationConfig:\n",
      "            \n",
      "        TreeBuilderConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Max Tokens: 100\n",
      "            Num Layers: 5\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Summarization Length: 100\n",
      "            Summarization Model: <__main__.GEMINISummarizationModel object at 0x000001C144FB56D0>\n",
      "            Embedding Models: {'EMB': <__main__.SBertEmbeddingModel object at 0x000001C119E0A410>}\n",
      "            Cluster Embedding Model: EMB\n",
      "        \n",
      "        Reduction Dimension: 10\n",
      "        Clustering Algorithm: RAPTOR_Clustering\n",
      "        Clustering Parameters: {}\n",
      "        \n",
      "            \n",
      "            \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.SBertEmbeddingModel object at 0x000001C119E0A410>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "            \n",
      "            QA Model: <__main__.GEMINIQAModel object at 0x000001C1002AC450>\n",
      "            Tree Builder Type: cluster\n",
      "        \n",
      "2025-01-15 21:47:59,628 - Creating Leaf Nodes\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  2.00s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "2025-01-15 21:48:19,847 - Created 90 Leaf Embeddings\n",
      "2025-01-15 21:48:19,847 - Building All Nodes\n",
      "2025-01-15 21:48:19,852 - Using Cluster TreeBuilder\n",
      "2025-01-15 21:48:19,852 - Constructing Layer 0\n",
      "d:\\DFKI\\RAGs\\raptor\\env\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "d:\\DFKI\\RAGs\\raptor\\env\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-15 21:48:47,867 - Summarization Length: 100\n",
      "2025-01-15 21:48:51,692 - Node Texts Length: 600, Summarized Text Length: 145\n",
      "Batches: 100%|██████████| 1/1 [00:08<00:00,  8.01s/it]\n",
      "2025-01-15 21:49:03,456 - Node Texts Length: 783, Summarized Text Length: 142\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "2025-01-15 21:49:07,264 - Node Texts Length: 898, Summarized Text Length: 150\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "2025-01-15 21:49:11,447 - Node Texts Length: 992, Summarized Text Length: 147\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "2025-01-15 21:49:15,419 - Node Texts Length: 487, Summarized Text Length: 151\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "2025-01-15 21:49:19,207 - Node Texts Length: 184, Summarized Text Length: 147\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "2025-01-15 21:49:23,056 - Node Texts Length: 259, Summarized Text Length: 141\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "2025-01-15 21:49:26,919 - Node Texts Length: 143, Summarized Text Length: 143\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "2025-01-15 21:49:31,002 - Node Texts Length: 520, Summarized Text Length: 148\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "2025-01-15 21:49:34,867 - Node Texts Length: 605, Summarized Text Length: 146\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s]\n",
      "2025-01-15 21:49:38,669 - Node Texts Length: 469, Summarized Text Length: 147\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "2025-01-15 21:49:42,568 - Node Texts Length: 239, Summarized Text Length: 141\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n",
      "2025-01-15 21:49:46,348 - Node Texts Length: 404, Summarized Text Length: 145\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]\n",
      "2025-01-15 21:49:50,136 - Node Texts Length: 452, Summarized Text Length: 152\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.47it/s]\n",
      "2025-01-15 21:49:53,749 - Node Texts Length: 607, Summarized Text Length: 145\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "2025-01-15 21:49:54,158 - Constructing Layer 1\n",
      "d:\\DFKI\\RAGs\\raptor\\env\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-01-15 21:50:22,136 - Summarization Length: 100\n",
      "2025-01-15 21:50:25,937 - Node Texts Length: 750, Summarized Text Length: 149\n",
      "Batches: 100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "2025-01-15 21:50:32,837 - Node Texts Length: 879, Summarized Text Length: 145\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "2025-01-15 21:50:36,849 - Node Texts Length: 586, Summarized Text Length: 145\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]\n",
      "2025-01-15 21:50:37,334 - Constructing Layer 2\n",
      "2025-01-15 21:50:37,334 - Stopping Layer construction: Cannot Create More Layers. Total Layers in tree: 2\n",
      "2025-01-15 21:50:37,336 - Successfully initialized TreeRetriever with Config \n",
      "        TreeRetrieverConfig:\n",
      "            Tokenizer: <Encoding 'cl100k_base'>\n",
      "            Threshold: 0.5\n",
      "            Top K: 5\n",
      "            Selection Mode: top_k\n",
      "            Context Embedding Model: EMB\n",
      "            Embedding Model: <__main__.SBertEmbeddingModel object at 0x000001C119E0A410>\n",
      "            Num Layers: None\n",
      "            Start Layer: None\n",
      "        \n",
      "2025-01-15 21:50:37,336 - Using collapsed_tree\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "2025-01-15 21:50:39,271 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How big is the ANTISCAM dataset? \n",
      "Answer:  **The AntiScam dataset consists of 220 human-human text conversations.**\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 12.42it/s]\n",
      "2025-01-15 21:50:44,709 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How is intent annotated?\n",
      "Answer:  The text describes a **hierarchical intent annotation scheme** for dialogue systems, particularly effective for non-collaborative tasks like scam detection. Here's how it works:\n",
      "\n",
      "1. **Intent Separation:** Intents are divided into two main categories:\n",
      "   - **On-task Intents:** These represent key actions specific to the task. For instance, in the AntiScam dataset, on-task intents include *elicitation*, *providing_information*, and *refusal*.\n",
      "   - **Off-task Intents:** These capture general conversational elements not tied to the specific task. Instead of creating task-specific categories, common dialogue acts are used. Examples include *open_question*, *yes_no_question*, *positive_answer*, *greeting*, *closing*, etc.\n",
      "\n",
      "2. **Annotation Process:**\n",
      "   - **On-task intents** are annotated directly based on the defined task-specific categories.\n",
      "   - **Off-task intents** are labeled using the general dialogue act categories.\n",
      "\n",
      "3. **Example:** In the AntiScam dataset:\n",
      "   - \"Can you share your bank account details?\" would be annotated with the on-task intent \"elicitation.\"\n",
      "   - \"Is that your final answer?\" would\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
      "2025-01-15 21:50:46,996 - Using collapsed_tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the baselines outperformed by this work?\n",
      "Answer:  The baselines outperformed by MISSA are:\n",
      "\n",
      "* **TransferTransfo:**  A vanilla Transformer-based model. MISSA improves upon this by adding intent and slot classifiers, highlighting their importance.\n",
      "* **Hybrid Model:** This model combines the vanilla TransferTransfo with elements of MISSA.  However, MISSA still outperforms it, suggesting the effectiveness of its overall architecture and design.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the evaluation metrics and criteria used to evaluate the model performance?\n",
      "Answer:  The evaluation of the dialogue system employs two main approaches: **Automatic Evaluation** and **Human Evaluation**, each encompassing several metrics:\n",
      "\n",
      "**Automatic Evaluation:**\n",
      "\n",
      "* **Perplexity:** This metric measures the language model's ability to predict the next word in a sequence, essentially assessing its fluency and understanding of language. Lower perplexity scores indicate better performance.\n",
      "\n",
      "* **Response-Intent Prediction (RIP) & Response-Slot Prediction (RSP):**  These metrics evaluate the alignment between the system's responses and the user's intents. RIP focuses on recognizing the intention behind the user's input, while RSP aims to extract specific information (slots) relevant to the identified intent. \n",
      "\n",
      "* **Extended RIP & RSP (ERIP & ERSP):** These extend the basic RIP and RSP by acknowledging that multiple system intents might be valid responses to a single user intent. They evaluate the coherence of the dialogue by considering a broader range of acceptable system responses.\n",
      "\n",
      "**Human Evaluation:**\n",
      "\n",
      "* **Fluency:** This metric evaluates the naturalness and grammatical correctness of the system's generated language.\n",
      "\n",
      "* **Coherence:** This assesses the logical flow and consistency of the system's responses within the context of the ongoing conversation.\n",
      "\n",
      "* **Engagement:**\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sync experiments\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "data_path = \"data\\\\qasper-test-v0.3.0.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "    i = 2\n",
    "    selected_data = test_data[:i]\n",
    "    for sample in selected_data:\n",
    "        doc = sample[\"title\"]\n",
    "        doc += \"\\n\\n\"\n",
    "        doc += \"abstract\" + \"\\n\"\n",
    "        doc += sample[\"abstract\"] + \"\\n\\n\"\n",
    "        paragraphs = sample[\"full_text\"][\"paragraphs\"]\n",
    "        names = sample[\"full_text\"][\"section_name\"]\n",
    "        for name, paras in zip(names, paragraphs):\n",
    "            doc += name + \"\\n\"\n",
    "            doc += \"\\n\".join(paras)\n",
    "            doc += \"\\n\\n\"\n",
    "            \n",
    "        doc += \"figures_and_tables\\n\"\n",
    "        doc += \"\\n\".join(sample[\"figures_and_tables\"][\"caption\"])\n",
    "        # print(doc)\n",
    "        RA = RetrievalAugmentation(config=RAC)\n",
    "        RA.add_documents(doc)\n",
    "        results = []\n",
    "        for idx in range(len(sample[\"qas\"][\"question\"])):\n",
    "            question_id = sample[\"qas\"][\"question_id\"][idx]\n",
    "            question = sample[\"qas\"][\"question\"][idx]\n",
    "            answer = RA.answer_question(question=question)\n",
    "            # print(\"Question: \", question)\n",
    "            # print(\"Answer: \", answer)\n",
    "            # print(\"\\n\\n\")\n",
    "            results.append({\"question_id\": question_id, \"question\": question, \n",
    "                       \"predicted_evidence\": \"\", \"predicted_answer\":answer})\n",
    "            \n",
    "        paper_id = sample[\"id\"]\n",
    "        folder_path = \"results/outputs\"\n",
    "        res_path = os.path.join(folder_path, f\"{paper_id}.jsonl\")\n",
    "        with open(res_path, \"w\") as f:\n",
    "            for res in results:\n",
    "                json.dump(res, f)\n",
    "                f.write(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "550bed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evaluation script\n",
    "\n",
    "import os\n",
    "\n",
    "results_folder = \"./results/outputs\"\n",
    "combine_file = \"./results/combine.jsonl\"\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    print(f\"Results folder does not exist: {results_folder}\")\n",
    "    \n",
    "with open(combine_file, 'w') as outfile:\n",
    "    for file_name in os.listdir(results_folder):\n",
    "        if not file_name.endswith(\".jsonl\"):\n",
    "            continue\n",
    "        file_path = os.path.join(results_folder, file_name)\n",
    "        # print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        with open(file_path, 'r') as infile:\n",
    "            for line in infile:\n",
    "                outfile.write(line)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a95295fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Answer F1\": 0.17125569173872984,\n",
      "  \"Answer F1 by type\": {\n",
      "    \"extractive\": 0.24224082245395526,\n",
      "    \"abstractive\": 0.14807017674597192,\n",
      "    \"boolean\": 0.015831517792302106,\n",
      "    \"none\": 0.0\n",
      "  },\n",
      "  \"Evidence F1\": 0.27058823529411763\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%run evaluation-qasper.py --predictions {combine_file} --gold ./data/qasper-test-v0.3.0.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fa62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
